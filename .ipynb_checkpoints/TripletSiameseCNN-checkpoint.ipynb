{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Siamese Convolutional Neural Network<br>Triplet Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import siamese_CNN_triplet\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import pickle\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "\n",
    "# model imports\n",
    "from keras.models import Sequential, Model, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.layers import Dropout, BatchNormalization\n",
    "from keras.layers import Lambda, concatenate\n",
    "\n",
    "from keras.initializers import RandomNormal\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# plotting\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import pydotplus as pydot\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(i):\n",
    "    print(\"\\nLoading dataset...\", end=\"\")\n",
    "\n",
    "    data = load_pickle(PATHS[i][0])  # training data\n",
    "\n",
    "    pairs = load_pickle(PATHS[i][1])  # pairs of data\n",
    "    pairs = [pairs[0], pairs[1]]\n",
    "\n",
    "    targets = load_pickle(PATHS[i][2])  # targets of the data\n",
    "\n",
    "    print(\"dataset {0} loaded successfully!\\n\".format(PATHS.index(PATHS[i])))\n",
    "\n",
    "    return data, pairs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_shapes():\n",
    "    print(\"\\nNumber of classes               : \", data.shape[0])\n",
    "    print(\"Original signatures             : \", len(data[0][0]))\n",
    "    print(\"Forged signatures               : \", len(data[0][1]))\n",
    "    print(\"Image shape                     : \", data[0][0][0].shape)\n",
    "    print(\"Total number of pairs           : \", pairs[0].shape[0])\n",
    "    print(\"Number of pairs for each class  : \", pairs[0].shape[0]//data.shape[0])\n",
    "    print(\"Targets shape                   : \", targets.shape)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_13(id1, id2, id3):\n",
    "    fig, ax = plt.subplots(1, 3, sharex=True, sharey=True, figsize=(8,8))\n",
    "\n",
    "    ax[0].imshow(pairs[0][id1])\n",
    "    ax[1].imshow(pairs[1][id2])\n",
    "    ax[2].imshow(pairs[1][id3])\n",
    "    # subplot titles\n",
    "    ax[0].set_title('Anchor image of class {0}'.format(id1//42))\n",
    "    ax[1].set_title('Target: {0}'.format(targets[id2]))\n",
    "    ax[2].set_title('Target: {0}'.format(targets[id3]))\n",
    "\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(y_true, y_pred):\n",
    "    \"\"\"Compute triplet loss.\n",
    "    \n",
    "    Args:\n",
    "        y_true : true values.\n",
    "        y_pred : predicted values.\n",
    "\n",
    "    Returns:\n",
    "        triplet loss.\n",
    "    \"\"\"\n",
    "    alpha = 0.5\n",
    "    anchor, positive, negative = y_pred[0,\n",
    "                                        0:512], y_pred[0, 512:1024], y_pred[0, 1024:1536]\n",
    "\n",
    "    positive_distance = K.mean(K.square(anchor - positive), axis=-1)\n",
    "    negative_distance = K.mean(K.square(anchor - negative), axis=-1)\n",
    "\n",
    "    return K.mean(K.maximum(0.0, positive_distance - negative_distance + alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_setup(verbose=False):\n",
    "    rms = RMSprop(lr=1e-4, rho=0.9, epsilon=1e-08)\n",
    "\n",
    "    model = siamese_CNN_triplet((224, 224, 1))\n",
    "    model.compile(optimizer=rms, loss=triplet_loss)\n",
    "\n",
    "    if verbose:\n",
    "        model.summary()\n",
    "\n",
    "        tf.keras.utils.plot_model(\n",
    "            model,\n",
    "            show_shapes=True,\n",
    "            show_layer_names=True,\n",
    "            to_file=\"resources\\\\model_plot.png\"\n",
    "        )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training(model, weights_name):\n",
    "    print(\"\\nStarting training!\\n\")\n",
    "\n",
    "    # hyperparameters\n",
    "    EPOCHS = 100  # number of epochs\n",
    "    BS = 32  # batch size\n",
    "\n",
    "    # callbacks\n",
    "    callbacks = [EarlyStopping(monitor='val_loss', patience=3, verbose=1,)]\n",
    "\n",
    "    history = model.fit(\n",
    "        pairs, targets,\n",
    "        batch_size=BS,\n",
    "        epochs=EPOCHS,\n",
    "        verbose=1,\n",
    "        callbacks=callbacks,\n",
    "        validation_split=0.25,\n",
    "    )\n",
    "\n",
    "    ALL_HISTORY.append(history)\n",
    "    \n",
    "    print(\"\\nSaving weight for model...\", end=\"\")\n",
    "    siamese_net.save_weights('weights\\\\{0}.h5'.format(weights_name))\n",
    "    print(\"saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy_roc(predictions, labels):\n",
    "    \"\"\"Compute ROC accuracyand threshold.\n",
    "\n",
    "    Also, plot FAR-FRR curves and P-R curves for input data.\n",
    "    \n",
    "    Args:\n",
    "        predictions -- np.array : array of predictions.\n",
    "        labels -- np.array : true labels (0 or 1).\n",
    "        plot_far_frr -- bool : plots curves of True.\n",
    "    \n",
    "    Returns:\n",
    "        max_acc -- float : maximum accuracy of model.\n",
    "        best_thresh --float : best threshold for the model.\n",
    "    \"\"\"\n",
    "    dmax = np.max(predictions)\n",
    "    dmin = np.min(predictions)\n",
    "\n",
    "    nsame = np.sum(labels == 1)  #similar\n",
    "    ndiff = np.sum(labels == 0)  #different\n",
    "\n",
    "    step = 0.01\n",
    "    max_acc = 0\n",
    "    best_thresh = -1\n",
    "\n",
    "    frr_plot = []\n",
    "    far_plot = []\n",
    "    pr_plot = []\n",
    "    re_plot = []\n",
    "\n",
    "    ds = []\n",
    "    for d in np.arange(dmin, dmax+step, step):\n",
    "        idx1 = predictions.ravel() <= d  # guessed genuine\n",
    "        idx2 = predictions.ravel() > d  # guessed forged\n",
    "\n",
    "        tp = float(np.sum(labels[idx1] == 1))\n",
    "        tn = float(np.sum(labels[idx2] == 0))\n",
    "        fp = float(np.sum(labels[idx1] == 0))\n",
    "        fn = float(np.sum(labels[idx2] == 1))\n",
    "\n",
    "        tpr = float(np.sum(labels[idx1] == 1)) / nsame       \n",
    "        tnr = float(np.sum(labels[idx2] == 0)) / ndiff\n",
    "        \n",
    "        \n",
    "        acc = 0.5 * (tpr + tnr)\n",
    "        pr = tp / (tp + fp)\n",
    "        re = tp / (tp + fn)\n",
    "       \n",
    "        if (acc > max_acc):\n",
    "            max_acc, best_thresh = acc, d\n",
    "\n",
    "        far = fp / (fp + tn)\n",
    "        frr = fn / (fn + tp)\n",
    "        frr_plot.append(frr)\n",
    "        pr_plot.append(pr)\n",
    "        re_plot.append(re)\n",
    "        far_plot.append(far)\n",
    "        ds.append(d)\n",
    "\n",
    "    plot_metrics = [ds, far_plot, frr_plot, pr_plot, re_plot]\n",
    "\n",
    "    return max_acc, best_thresh, plot_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation(model):\n",
    "    print(\"\\nEvaluating model...\", end=\"\")\n",
    "\n",
    "    pred = model.predict(pairs)\n",
    "    acc, thresh, plot_metrics = compute_accuracy_roc(pred, targets)\n",
    "    \n",
    "    print(\"evaluation finished!\\n\")\n",
    "\n",
    "    ACCURACIES.append(acc)\n",
    "    THRESHOLDS.append(thresh)\n",
    "    PLOTS.append(plot_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_history():\n",
    "    losses = ['loss', 'val_loss']\n",
    "    accs = ['accuracy', 'val_accuracy']\n",
    "\n",
    "    fig, ax = plt.subplots(3, 2, sharex=True, sharey=True, figsize=(8,8))\n",
    "    for i in range(3):\n",
    "        for x, y in zip(losses, accs):\n",
    "            ax[i,0].plot(ALL_HISTORY[i].history[x])\n",
    "            ax[i,0].set_title('Losses')\n",
    "\n",
    "            ax[i,1].plot(ALL_HISTORY[i].history[y])\n",
    "            ax[i,1].set_title('Accuracies')\n",
    "\n",
    "        ax[i,0].legend(losses)\n",
    "        ax[i,1].legend(accs)\n",
    "\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_plots(metrics):\n",
    "    ds = metrics[0]\n",
    "    far_plot = metrics[1]\n",
    "    frr_plot = metrics[2]\n",
    "    pr_plot = metrics[3]\n",
    "    re_plot = metrics[4]\n",
    "\n",
    "    fig = plt.figure(figsize=(15,6))\n",
    "    # error rate\n",
    "    ax = fig.add_subplot(121)\n",
    "    ax.plot(ds, far_plot, color='red')\n",
    "    ax.plot(ds, frr_plot, color='blue')\n",
    "    ax.set_title('Error rate')\n",
    "    ax.legend(['FAR', 'FRR'])\n",
    "    ax.set(xlabel = 'Thresholds', ylabel='Error rate')\n",
    "\n",
    "    # precision-recall curve\n",
    "    ax1 = fig.add_subplot(122)\n",
    "    ax1.plot(ds, pr_plot, color='green')\n",
    "    ax1.plot(ds, re_plot, color='magenta')\n",
    "    ax1.set_title('P-R curve')\n",
    "    ax1.legend(['Precision', 'Recall'])\n",
    "    ax.set(xlabel = 'Thresholds', ylabel='Error rate')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Everything put together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths to datasets\n",
    "PATHS = [\n",
    "    [\n",
    "        'data\\\\pickle-files\\\\cedar_pairs1_train.pickle',\n",
    "        'data\\\\pickle-files\\\\cedar_pairs1_pairs.pickle',\n",
    "        'data\\\\pickle-files\\\\cedar_pairs1_targets.pickle'\n",
    "    ],\n",
    "    [\n",
    "        \"data\\\\pickle-files\\\\bengali_pairs1_pairs.pickle\"\n",
    "        'data\\\\pickle-files\\\\bengali_pairs1_train.pickle',\n",
    "        'data\\\\pickle-files\\\\bengali_pairs1_targets.pickle'\n",
    "    ],\n",
    "    [\n",
    "        'data\\\\pickle-files\\\\hindi_pairs1_train.pickle',\n",
    "        'data\\\\pickle-files\\\\hindi_pairs1_pairs.pickle',\n",
    "        'data\\\\pickle-files\\\\hindi_pairs1_targets.pickle'\n",
    "    ]\n",
    "]\n",
    "\n",
    "# for kaggle\n",
    "# PATHS = [\n",
    "#     [\n",
    "#         '../usr/lib/preprocess/cedar_pairs1_train.pickle',\n",
    "#         '../usr/lib/preprocess/cedar_pairs1_pairs.pickle',\n",
    "#         '../usr/lib/preprocess/cedar_pairs1_targets.pickle'\n",
    "#     ],\n",
    "#     [\n",
    "#         '../usr/lib/preprocess/bengali_pairs1_train.pickle',\n",
    "#         '../usr/lib/preprocess/bengali_pairs1_pairs.pickle',\n",
    "#         '../usr/lib/preprocess/bengali_pairs1_targets.pickle'\n",
    "#     ],\n",
    "#     [\n",
    "#         '../usr/lib/preprocess/hindi_pairs1_train.pickle',\n",
    "#         '../usr/lib/preprocess/hindi_pairs1_pairs.pickle',\n",
    "#         '../usr/lib/preprocess/hindi_pairs1_targets.pickle'\n",
    "#     ]\n",
    "# ]\n",
    "\n",
    "# evaluation\n",
    "ALL_HISTORY = []\n",
    "ACCURACIES = []\n",
    "THRESHOLDS = []\n",
    "PLOTS = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    data, pairs, targets = load_dataset(i)\n",
    "\n",
    "    data_shapes()\n",
    "\n",
    "    for bs in range(0, 3*42, 42):\n",
    "        plot_13(0+bs, 20+bs, 41+bs)\n",
    "        print()\n",
    "\n",
    "    if i == 0:\n",
    "        siamese_net = model_setup(True)\n",
    "        model_training(siamese_net, 'siamese_cedar')\n",
    "\n",
    "    elif i == 1:\n",
    "        siamese_net = model_setup()\n",
    "        model_training(siamese_net, 'siamese_bengali')\n",
    "\n",
    "    elif i == 2:\n",
    "        siamese_net = model_setup()\n",
    "        model_training(siamese_net, 'siamese_hindi')\n",
    "    \n",
    "    model_evaluation(siamese_net)\n",
    "\n",
    "    del data\n",
    "    del pairs\n",
    "    del targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame.from_dict({'Accuracies': ACCURACIES,\n",
    "                          'Thresholds': THRESHOLDS})\n",
    "df.index = ['Cedar', 'BhSig260 Bengali', 'BhSig260 Hindi']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for met in PLOTS:\n",
    "    evaluation_plots(met)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2fc04cdb9730b0f31da2f90a691cdd0fa9da7bc1222eb1adb5ee73ed7bedeaa9"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
