{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CEDAR dataset Signature Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import SiamesePairs, SiameseTriplets, SiameseQuadruplets\n",
    "from networks import *\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import pickle\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# plotting\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import pydotplus as pydot\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./weights'):\n",
    "    os.makedirs('./weights')\n",
    "    print(\"Weights directory created\")\n",
    "else:\n",
    "    print(\"Weights directory exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(training_mode, reset=False):\n",
    "    if training_mode == 'pairs':\n",
    "        return SiamesePairs(name=NAME,\n",
    "                            data_path=DATA_PATH,\n",
    "                            save_path=SAVE_PATH,\n",
    "                            channels=CHANNELS,\n",
    "                            size=SIZE,\n",
    "                            reset=reset)\n",
    "\n",
    "    elif training_mode == 'triplets':\n",
    "        return SiameseTriplets(name=NAME,\n",
    "                               data_path=DATA_PATH,\n",
    "                               save_path=SAVE_PATH,\n",
    "                               channels=CHANNELS,\n",
    "                               size=SIZE,\n",
    "                               reset=reset)\n",
    "\n",
    "    elif training_mode == 'quadruplets':\n",
    "        return SiameseQuadruplets(name=NAME,\n",
    "                                  data_path=DATA_PATH,\n",
    "                                  save_path=SAVE_PATH,\n",
    "                                  channels=CHANNELS,\n",
    "                                  size=SIZE,\n",
    "                                  reset=reset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_shapes(data):\n",
    "    print(\"\\nNumber of classes   : \", data.train_images.shape[0])\n",
    "    print(\"Original signatures : \", len(data.train_images[0][0]))\n",
    "    print(\"Forged signatures   : \", len(data.train_images[0][1]))\n",
    "    print(\"Image shape         : \", data.train_images[0][0][0].shape)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pairs(data, id1, id2, id3):\n",
    "    fig, ax = plt.subplots(1, 3, sharex=True, sharey=True, figsize=(8,8))\n",
    "\n",
    "    ax[0].imshow(data.pairs[0][id1])\n",
    "    ax[1].imshow(data.pairs[1][id2])\n",
    "    ax[2].imshow(data.pairs[1][id3])\n",
    "    # subplot titles\n",
    "    ax[0].set_title('Anchor image of class {0}'.format(id1//42))\n",
    "    ax[1].set_title('Target: {0}'.format(data.targets[id2]))\n",
    "    ax[2].set_title('Target: {0}'.format(data.targets[id3]))\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_triplets(data):\n",
    "    fig, ax = plt.subplots(1, 3, sharex=True, sharey=True, figsize=(8,8))\n",
    "\n",
    "    ax[0].imshow(data.triplets[0][0])\n",
    "    ax[1].imshow(data.triplets[1][0])\n",
    "    ax[2].imshow(data.triplets[2][0])\n",
    "    # subplot titles\n",
    "    ax[0].set_title('Anchor')\n",
    "    ax[1].set_title('Positive')\n",
    "    ax[2].set_title('Negative')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_quadruplets(data):\n",
    "    fig, ax = plt.subplots(1, 4, sharex=True, sharey=True, figsize=(8,8))\n",
    "\n",
    "    ax[0].imshow(data.quadruplets[0][0])\n",
    "    ax[1].imshow(data.quadruplets[1][0])\n",
    "    ax[2].imshow(data.quadruplets[2][0])\n",
    "    ax[3].imshow(data.quadruplets[3][0])\n",
    "    # subplot titles\n",
    "    ax[0].set_title('Anchor')\n",
    "    ax[1].set_title('Positive')\n",
    "    ax[2].set_title('Negative')\n",
    "    ax[3].set_title('Negative2')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_setup_pairs(training_mode, verbose=False):\n",
    "    \"\"\"Set up model for contrastive loss.\n",
    "    \n",
    "    Args:\n",
    "        training_mode -- str : mode of training model.\n",
    "        verbose -- bool : if True, prints model summary.\n",
    "    \n",
    "    Returns:\n",
    "        model : siamese model.\n",
    "    \"\"\"\n",
    "    # instantiating the model in the strategy scope\n",
    "    if IS_TPU:\n",
    "        with tpu_strategy.scope():\n",
    "            model = pairs_net(INPUT_SHAPE)\n",
    "\n",
    "    else:\n",
    "        model = pairs_net(INPUT_SHAPE)\n",
    "    \n",
    "    if verbose:\n",
    "        model.summary()\n",
    "        tf.keras.utils.plot_model(\n",
    "            model,\n",
    "            show_shapes=True,\n",
    "            show_layer_names=True,\n",
    "            to_file=\"ModelPlot{0}.png\".format(training_mode.upper())\n",
    "        )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_setup_triplet(training_mode, verbose=False):\n",
    "    \"\"\"Set up model for triplet loss.\n",
    "    \n",
    "    Args:\n",
    "        training_mode -- str : mode of training model.\n",
    "        verbose -- bool : if True, prints model summary.\n",
    "    \n",
    "    Returns:\n",
    "        model : siamese model.\n",
    "    \"\"\"\n",
    "    # instantiating the model in the strategy scope\n",
    "    if IS_TPU:\n",
    "        with tpu_strategy.scope():\n",
    "            siamese_network = triplet_net(INPUT_SHAPE)\n",
    "            model = TripletModel(siamese_network)\n",
    "            model.compile(optimizer=Adam(0.0001))\n",
    "\n",
    "    else:\n",
    "        siamese_network = triplet_net(INPUT_SHAPE)\n",
    "        model = TripletModel(siamese_network)\n",
    "        model.compile(optimizer=Adam(0.0001))\n",
    "\n",
    "    if verbose:\n",
    "        siamese_network.summary()\n",
    "        tf.keras.utils.plot_model(\n",
    "            siamese_network,\n",
    "            show_shapes=True,\n",
    "            show_layer_names=True,\n",
    "            to_file=\"ModelPlot{0}.png\".format(training_mode.upper())\n",
    "        )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_setup_quadruplet(training_mode, verbose=False):\n",
    "    \"\"\"Set up model for quadruplet loss.\n",
    "    \n",
    "    Args:\n",
    "        training_mode -- str : mode of training model.\n",
    "        verbose -- bool : if True, prints model summary.\n",
    "    \n",
    "    Returns:\n",
    "        model : siamese model.\n",
    "    \"\"\"\n",
    "    # instantiating the model in the strategy scope\n",
    "    if IS_TPU:\n",
    "        with tpu_strategy.scope():\n",
    "            siamese_network = quadruplet_net(INPUT_SHAPE)\n",
    "            model = QuadrupletModel(siamese_network)\n",
    "            model.compile(optimizer=Adam(0.0001))\n",
    "\n",
    "\n",
    "    else:\n",
    "        siamese_network = quadruplet_net(INPUT_SHAPE)\n",
    "        model = QuadrupletModel(siamese_network)\n",
    "        model.compile(optimizer=Adam(0.0001))\n",
    "\n",
    "    if verbose:\n",
    "        siamese_network.summary()\n",
    "        tf.keras.utils.plot_model(\n",
    "            siamese_network,\n",
    "            show_shapes=True,\n",
    "            show_layer_names=True,\n",
    "            to_file=\"ModelPlot{0}.png\".format(training_mode.upper())\n",
    "        )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training(data, model, training_mode, weights_name):\n",
    "    \"\"\"Training the model and saving its weights.\n",
    "\n",
    "    Args:\n",
    "        data : dataset.\n",
    "        model : model to be trained\n",
    "        weights_name -- str : name for weights.\n",
    "    \"\"\"\n",
    "    if training_mode == 'pairs':\n",
    "        X = [data.pairs[0], data.pairs[1]]\n",
    "        y = data.targets\n",
    "\n",
    "    elif training_mode == 'triplets':\n",
    "        X = data.triplets\n",
    "        y = None\n",
    "\n",
    "    elif training_mode == 'quadruplets':\n",
    "        X = data.quadruplets\n",
    "        y = None\n",
    "\n",
    "    print(\"\\n---------- Starting training! ----------\\n\")\n",
    "\n",
    "    # hyperparameters\n",
    "    EPOCHS = 100  # number of epochs\n",
    "    BS = 128  # batch size\n",
    "\n",
    "    # callbacks\n",
    "    callbacks = [EarlyStopping(monitor='val_loss', patience=3, verbose=1,)]\n",
    "\n",
    "    history = model.fit(\n",
    "        X, y,\n",
    "        batch_size=BS,\n",
    "        epochs=EPOCHS,\n",
    "        verbose=1,\n",
    "        callbacks=callbacks,\n",
    "        validation_split=0.3,\n",
    "    )\n",
    "\n",
    "    ALL_HISTORY.append(history)\n",
    "\n",
    "    print(\"\\nSaving weights for model...\", end=\"\")\n",
    "    model.save_weights('./weights/{0}.h5'.format(weights_name))\n",
    "    print(\"saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_history():\n",
    "    losses = ['loss', 'val_loss']\n",
    "\n",
    "    fig, ax = plt.subplots(1, 3, sharex=True, sharey=True, figsize=(13,4))\n",
    "    for i in range(3):\n",
    "        for x in losses:\n",
    "            ax[i].plot(ALL_HISTORY[i].history[x])\n",
    "            ax[i].set_title('Losses')\n",
    "\n",
    "        ax[i].legend(losses)\n",
    "        ax[i].grid(True)\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Everything put together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_PATH = \"../input/handwritten-signature-datasets/CEDAR/CEDAR\"  # path to dataset (kaggle)\n",
    "# SAVE_PATH = \"./\"                                                   # path to save pickle files (kaggle)\n",
    "\n",
    "DATA_PATH = \"data\\\\CEDAR\"             # path to dataset\n",
    "SAVE_PATH = \"data\\\\pickle-files\"      # path to save pickle files\n",
    "\n",
    "CLASSES = len(os.listdir(DATA_PATH))  # number of classes\n",
    "NAME = \"CEDAR\"\n",
    "\n",
    "# size of images\n",
    "SIZE = 224\n",
    "CHANNELS = 1\n",
    "INPUT_SHAPE = (SIZE, SIZE, CHANNELS)\n",
    "\n",
    "# evaluation\n",
    "ALL_HISTORY = []\n",
    "ACCURACIES = []\n",
    "THRESHOLDS = []\n",
    "PLOTS = []\n",
    "\n",
    "TO_RESET = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_TPU = False\n",
    "\n",
    "if IS_TPU:\n",
    "    # detect and init the TPU\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n",
    "\n",
    "    # instantiate a distribution strategy\n",
    "    tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PAIRS mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE = 'pairs'\n",
    "\n",
    "dataset = load_dataset(MODE, TO_RESET)  # loading dataset\n",
    "data_shapes(dataset)                    # seeing dataset\n",
    "plot_pairs(dataset, 0, 20, 41)          # plotting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up model and training\n",
    "model = model_setup_pairs(MODE, True)\n",
    "model_training(dataset, model, MODE, '{0}Siamese{1}'.format(NAME, MODE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dataset\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRIPLET mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE = 'triplets'\n",
    "\n",
    "dataset = load_dataset(MODE, TO_RESET)  # loading dataset\n",
    "data_shapes(dataset)                    # seeing dataset\n",
    "plot_triplets(dataset)                  # plotting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up model and training\n",
    "model = model_setup_triplet(MODE, True)\n",
    "model_training(dataset, model, MODE, '{0}Siamese{1}'.format(NAME, MODE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dataset\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUADRUPLET mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE = 'quadruplets'\n",
    "\n",
    "dataset = load_dataset(MODE, TO_RESET)  # loading dataset\n",
    "data_shapes(dataset)                    # seeing dataset\n",
    "plot_quadruplets(dataset)               # plotting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up model and training\n",
    "model = model_setup_quadruplet(MODE, True)\n",
    "model_training(dataset, model, MODE, '{0}Siamese{1}'.format(NAME, MODE))\n",
    "model_evaluation(model, MODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dataset\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing history for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame.from_dict({'Accuracies': ACCURACIES,\n",
    "                          'Thresholds': THRESHOLDS})\n",
    "df.index = ['Cedar', 'BhSig260 Bengali', 'BhSig260 Hindi']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for met in PLOTS:\n",
    "    evaluation_plots(met)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2fc04cdb9730b0f31da2f90a691cdd0fa9da7bc1222eb1adb5ee73ed7bedeaa9"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
