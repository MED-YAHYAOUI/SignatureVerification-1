{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1694f1c5",
   "metadata": {},
   "source": [
    "# Evaluating models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bab033b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import SiamesePairs, SiameseTriplets, SiameseQuadruplets\n",
    "from networks import *\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pandas import DataFrame\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.metrics import CosineSimilarity\n",
    "\n",
    "# plotting\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import pydotplus as pydot\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d49532e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(training_mode, reset=False):\n",
    "    if training_mode == 'pairs':\n",
    "        return SiamesePairs(name=NAME,\n",
    "                            data_path=DATA_PATH,\n",
    "                            save_path=SAVE_PATH,\n",
    "                            channels=CHANNELS,\n",
    "                            size=SIZE,\n",
    "                            reset=reset)\n",
    "\n",
    "    elif training_mode == 'triplets':\n",
    "        return SiameseTriplets(name=NAME,\n",
    "                               data_path=DATA_PATH,\n",
    "                               save_path=SAVE_PATH,\n",
    "                               channels=CHANNELS,\n",
    "                               size=SIZE,\n",
    "                               reset=reset)\n",
    "\n",
    "    elif training_mode == 'quadruplets':\n",
    "        return SiameseQuadruplets(name=NAME,\n",
    "                                  data_path=DATA_PATH,\n",
    "                                  save_path=SAVE_PATH,\n",
    "                                  channels=CHANNELS,\n",
    "                                  size=SIZE,\n",
    "                                  reset=reset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7b4e4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_shapes(data):\n",
    "    print(\"\\nNumber of classes   : \", data.train_images.shape[0])\n",
    "    print(\"Original signatures : \", len(data.train_images[0][0]))\n",
    "    print(\"Forged signatures   : \", len(data.train_images[0][1]))\n",
    "    print(\"Image shape         : \", data.train_images[0][0][0].shape)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81549ed0",
   "metadata": {},
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82b5ed0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_setup_pairs(training_mode, verbose=False):\n",
    "    \"\"\"Set up model for contrastive loss.\n",
    "    \n",
    "    Args:\n",
    "        training_mode -- str : mode of training model.\n",
    "        verbose -- bool : if True, prints model summary.\n",
    "    \n",
    "    Returns:\n",
    "        model : siamese model.\n",
    "    \"\"\"\n",
    "    # instantiating the model in the strategy scope\n",
    "    if IS_TPU:\n",
    "        with tpu_strategy.scope():\n",
    "            model = pairs_net(INPUT_SHAPE)\n",
    "\n",
    "    else:\n",
    "        model = pairs_net(INPUT_SHAPE)\n",
    "    \n",
    "    if verbose:\n",
    "        model.summary()\n",
    "        tf.keras.utils.plot_model(\n",
    "            model,\n",
    "            show_shapes=True,\n",
    "            show_layer_names=True,\n",
    "            to_file=\"{0}_ModelPlot{1}.png\".format(NAME, training_mode.upper())\n",
    "        )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64a9f30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_setup_triplet(training_mode, verbose=False):\n",
    "    \"\"\"Set up model for triplet loss.\n",
    "    \n",
    "    Args:\n",
    "        training_mode -- str : mode of training model.\n",
    "        verbose -- bool : if True, prints model summary.\n",
    "    \n",
    "    Returns:\n",
    "        model : siamese model.\n",
    "    \"\"\"\n",
    "    # instantiating the model in the strategy scope\n",
    "    if IS_TPU:\n",
    "        with tpu_strategy.scope():\n",
    "            siamese_network = triplet_net(INPUT_SHAPE)\n",
    "            model = TripletModel(siamese_network)\n",
    "            model.compile(optimizer=Adam(0.0001))\n",
    "\n",
    "    else:\n",
    "        siamese_network = triplet_net(INPUT_SHAPE)\n",
    "        model = TripletModel(siamese_network)\n",
    "        model.compile(optimizer=Adam(0.0001))\n",
    "\n",
    "    if verbose:\n",
    "        siamese_network.summary()\n",
    "        tf.keras.utils.plot_model(\n",
    "            siamese_network,\n",
    "            show_shapes=True,\n",
    "            show_layer_names=True,\n",
    "            to_file=\"{0}_ModelPlot{1}.png\".format(NAME, training_mode.upper())\n",
    "        )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53ed3626",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_setup_quadruplet(training_mode, verbose=False):\n",
    "    \"\"\"Set up model for quadruplet loss.\n",
    "    \n",
    "    Args:\n",
    "        training_mode -- str : mode of training model.\n",
    "        verbose -- bool : if True, prints model summary.\n",
    "    \n",
    "    Returns:\n",
    "        model : siamese model.\n",
    "    \"\"\"\n",
    "    # instantiating the model in the strategy scope\n",
    "    if IS_TPU:\n",
    "        with tpu_strategy.scope():\n",
    "            siamese_network = quadruplet_net(INPUT_SHAPE)\n",
    "            model = QuadrupletModel(siamese_network)\n",
    "            model.compile(optimizer=Adam(0.0001))\n",
    "\n",
    "\n",
    "    else:\n",
    "        siamese_network = quadruplet_net(INPUT_SHAPE)\n",
    "        model = QuadrupletModel(siamese_network)\n",
    "        model.compile(optimizer=Adam(0.0001))\n",
    "\n",
    "    if verbose:\n",
    "        siamese_network.summary()\n",
    "        tf.keras.utils.plot_model(\n",
    "            siamese_network,\n",
    "            show_shapes=True,\n",
    "            show_layer_names=True,\n",
    "            to_file=\"{0}_ModelPlot{1}.png\".format(NAME, training_mode.upper())\n",
    "        )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c5a1e5",
   "metadata": {},
   "source": [
    "## PAIRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58353615",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy_roc(predictions, labels):\n",
    "    \"\"\"Compute ROC accuracyand threshold.\n",
    "\n",
    "    Also, plot FAR-FRR curves and P-R curves for input data.\n",
    "    \n",
    "    Args:\n",
    "        predictions -- np.array : array of predictions.\n",
    "        labels -- np.array : true labels (0 or 1).\n",
    "        plot_far_frr -- bool : plots curves of True.\n",
    "    \n",
    "    Returns:\n",
    "        max_acc -- float : maximum accuracy of model.\n",
    "        best_thresh --float : best threshold for the model.\n",
    "    \"\"\"\n",
    "    dmax = np.max(predictions)\n",
    "    dmin = np.min(predictions)\n",
    "\n",
    "    nsame = np.sum(labels == 1)  #similar\n",
    "    ndiff = np.sum(labels == 0)  #different\n",
    "\n",
    "    step = 0.01\n",
    "    max_acc = 0\n",
    "    best_thresh = -1\n",
    "\n",
    "    frr_plot = []\n",
    "    far_plot = []\n",
    "    pr_plot = []\n",
    "    re_plot = []\n",
    "\n",
    "    ds = []\n",
    "    for d in np.arange(dmin, dmax+step, step):\n",
    "        idx1 = predictions.ravel() <= d  # guessed genuine\n",
    "        idx2 = predictions.ravel() > d   # guessed forged\n",
    "\n",
    "        tp = float(np.sum(labels[idx1] == 1))\n",
    "        tn = float(np.sum(labels[idx2] == 0))\n",
    "        fp = float(np.sum(labels[idx1] == 0))\n",
    "        fn = float(np.sum(labels[idx2] == 1))\n",
    "\n",
    "        tpr = float(np.sum(labels[idx1] == 1)) / nsame       \n",
    "        tnr = float(np.sum(labels[idx2] == 0)) / ndiff\n",
    "        \n",
    "        \n",
    "        acc = 0.5 * (tpr + tnr)\n",
    "        pr = tp / (tp + fp)\n",
    "        re = tp / (tp + fn)\n",
    "       \n",
    "        if (acc > max_acc):\n",
    "            max_acc, best_thresh = acc, d\n",
    "\n",
    "        far = fp / (fp + tn)\n",
    "        frr = fn / (fn + tp)\n",
    "        frr_plot.append(frr)\n",
    "        pr_plot.append(pr)\n",
    "        re_plot.append(re)\n",
    "        far_plot.append(far)\n",
    "        ds.append(d)\n",
    "\n",
    "    plot_metrics = [ds, far_plot, frr_plot, pr_plot, re_plot]\n",
    "\n",
    "    return max_acc, best_thresh, plot_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33737cd5",
   "metadata": {},
   "source": [
    "## TRIPLETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f2fe125a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_distance(data):\n",
    "    X = data.triplets\n",
    "    bs = data.triplets[0].shape[0]\n",
    "\n",
    "    pos = []\n",
    "    neg = []\n",
    "\n",
    "    for i in tqdm(range(bs)):\n",
    "        # load test data\n",
    "        anchor = np.array([X[0][i]])\n",
    "        positive = np.array([X[1][i]])\n",
    "        negative = np.array([X[2][i]])\n",
    "\n",
    "        # load embedding\n",
    "        model = triplet_net()\n",
    "        model.load_weights(r\"weights\\all3\\CEDARSiamesetriplets.h5\")\n",
    "        embedding = model.get_layer('sequential_network')\n",
    "\n",
    "        # getting embeddings\n",
    "        anchor_embedding, positive_embedding, negative_embedding = (\n",
    "            embedding(anchor),\n",
    "            embedding(positive),\n",
    "            embedding(negative),\n",
    "        )\n",
    "\n",
    "        cosine_similarity = CosineSimilarity()\n",
    "        positive_similarity = cosine_similarity(anchor_embedding, positive_embedding)\n",
    "        pos.append(positive_similarity.numpy())\n",
    "\n",
    "        negative_similarity = cosine_similarity(anchor_embedding, negative_embedding)\n",
    "        neg.append(negative_similarity.numpy())\n",
    "    \n",
    "    return (pos, neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9e0cf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_tripelts(preds):\n",
    "    pos_pred, neg_pred = preds\n",
    "    print(min(pos_pred), min(neg_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc44639",
   "metadata": {},
   "source": [
    "## QUADRUPLETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2659f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a1f318f",
   "metadata": {},
   "source": [
    "## Evaluate model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0dc27b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation(data, training_mode, model=None):\n",
    "    print(\"\\nEvaluating model...\", end=\"\")\n",
    "\n",
    "    if training_mode == 'pairs':\n",
    "        pred = model.predict(data.pairs)\n",
    "        acc, thresh, plot_metrics = compute_accuracy_roc(pred, data.targets)\n",
    "\n",
    "        ACCURACIES.append(acc)\n",
    "        THRESHOLDS.append(thresh)\n",
    "        PLOTS.append(plot_metrics)\n",
    "\n",
    "    elif training_mode == 'triplets':\n",
    "        preds = cosine_distance(data)\n",
    "#         evaluate_triplets(preds)\n",
    "        return preds\n",
    "\n",
    "    elif training_mode == 'quadruplets':\n",
    "        X = data.quadruplets\n",
    "        y = None\n",
    "\n",
    "    print(\"evaluation finished!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3a90865",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_plots(metrics):\n",
    "    ds = metrics[0]\n",
    "    far_plot = metrics[1]\n",
    "    frr_plot = metrics[2]\n",
    "    pr_plot = metrics[3]\n",
    "    re_plot = metrics[4]\n",
    "\n",
    "    fig = plt.figure(figsize=(15,7))\n",
    "    # error rate\n",
    "    ax = fig.add_subplot(121)\n",
    "    ax.plot(ds, far_plot, color='red')\n",
    "    ax.plot(ds, frr_plot, color='blue')\n",
    "    ax.set_title('Error rate')\n",
    "    ax.legend(['FAR', 'FRR'])\n",
    "    ax.set(xlabel = 'Thresholds', ylabel='Error rate')\n",
    "\n",
    "    # precision-recall curve\n",
    "    ax1 = fig.add_subplot(122)\n",
    "    ax1.plot(ds, pr_plot, color='green')\n",
    "    ax1.plot(ds, re_plot, color='magenta')\n",
    "    ax1.set_title('P-R curve')\n",
    "    ax1.legend(['Precision', 'Recall'])\n",
    "    ax.set(xlabel = 'Thresholds', ylabel='Error rate')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a722172",
   "metadata": {},
   "source": [
    "## Everything put together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc3c8b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_PATH = \"../input/handwritten-signature-datasets/CEDAR/CEDAR\"  # path to dataset (kaggle)\n",
    "# SAVE_PATH = \"./\"                                                   # path to save pickle files (kaggle)\n",
    "\n",
    "DATA_PATH = \"data\\\\CEDAR\"             # path to dataset\n",
    "SAVE_PATH = \"data\\\\pickle-files\"      # path to save pickle files\n",
    "\n",
    "CLASSES = len(os.listdir(DATA_PATH))  # number of classes\n",
    "NAME = \"CEDAR\"\n",
    "\n",
    "# size of images\n",
    "SIZE = 224\n",
    "CHANNELS = 1\n",
    "INPUT_SHAPE = (SIZE, SIZE, CHANNELS)\n",
    "\n",
    "# evaluation\n",
    "ACCURACIES = []\n",
    "THRESHOLDS = []\n",
    "PLOTS = []\n",
    "\n",
    "TO_RESET = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bda331c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE = 'pairs'\n",
    "\n",
    "dataset = load_dataset(MODE, TO_RESET)  # loading dataset\n",
    "data_shapes(dataset)                    # seeing dataset\n",
    "model = model_setup_pairs(MODE, True)   # setting up model and training\n",
    "model.load_weights()                    # load weights\n",
    "model_evaluation(model, MODE)           # evaluate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "94334119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training images loaded!\n",
      "\n",
      "\n",
      "Triplets loaded!\n",
      "\n",
      "\n",
      "Number of classes   :  55\n",
      "Original signatures :  24\n",
      "Forged signatures   :  24\n",
      "Image shape         :  (224, 224, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MODE = 'triplets'\n",
    "\n",
    "dataset = load_dataset(MODE, TO_RESET)   # loading dataset\n",
    "data_shapes(dataset)                     # seeing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c7077b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating model..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 660/660 [11:23<00:00,  1.04s/it]\n"
     ]
    }
   ],
   "source": [
    "pos_pred, neg_pred = model_evaluation(dataset, MODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c665f19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.96542 0.9644181\n",
      "1.0000001 0.99944067\n",
      "0.9961356618187645 0.992918205893401\n"
     ]
    }
   ],
   "source": [
    "print(min(pos_pred), min(neg_pred))\n",
    "print(max(pos_pred), max(neg_pred))\n",
    "print(sum(pos_pred)/660, sum(neg_pred)/660)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ad5732",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb244de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE = 'quadruplets'\n",
    "\n",
    "dataset = load_dataset(MODE, TO_RESET)      # loading dataset\n",
    "data_shapes(dataset)                        # seeing dataset\n",
    "model = model_setup_quadruplet(MODE, True)  # setting up model and training\n",
    "model.load_weights()                        # load weights\n",
    "model_evaluation(model, MODE)               # evaluate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fcb01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for met in PLOTS:\n",
    "    evaluation_plots(met)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
