{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Siamese Convolutional Neural Network<br>(Contrastive Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import siamese_CNN_contrastive\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import pickle\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# plotting\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import pydotplus as pydot\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(i):\n",
    "    print(\"\\nLoading dataset...\", end=\"\")\n",
    "\n",
    "    data = load_pickle(PATHS[i][0])  # training data\n",
    "\n",
    "    pairs = load_pickle(PATHS[i][1])  # pairs of data\n",
    "    pairs = [pairs[0], pairs[1]]\n",
    "\n",
    "    targets = load_pickle(PATHS[i][2])  # targets of the data\n",
    "\n",
    "    print(\"dataset {0} loaded successfully!\\n\".format(PATHS.index(PATHS[i])))\n",
    "\n",
    "    return data, pairs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_shapes():\n",
    "    print(\"\\nNumber of classes               : \", data.shape[0])\n",
    "    print(\"Original signatures             : \", len(data[0][0]))\n",
    "    print(\"Forged signatures               : \", len(data[0][1]))\n",
    "    print(\"Image shape                     : \", data[0][0][0].shape)\n",
    "    print(\"Total number of pairs           : \", pairs[0].shape[0])\n",
    "    print(\"Number of pairs for each class  : \", pairs[0].shape[0]//data.shape[0])\n",
    "    print(\"Targets shape                   : \", targets.shape)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_13(id1, id2, id3):\n",
    "    fig, ax = plt.subplots(1, 3, sharex=True, sharey=True, figsize=(8,8))\n",
    "\n",
    "    ax[0].imshow(pairs[0][id1])\n",
    "    ax[1].imshow(pairs[1][id2])\n",
    "    ax[2].imshow(pairs[1][id3])\n",
    "    # subplot titles\n",
    "    ax[0].set_title('Anchor image of class {0}'.format(id1//42))\n",
    "    ax[1].set_title('Target: {0}'.format(targets[id2]))\n",
    "    ax[2].set_title('Target: {0}'.format(targets[id3]))\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_setup_contrastive(verbose=False):\n",
    "\n",
    "    if IS_TPU:\n",
    "        # instantiating the model in the strategy scope\n",
    "        # creates the model on the TPU\n",
    "        with tpu_strategy.scope():\n",
    "            model = siamese_CNN_contrastive((224, 224, 1))\n",
    "    else:\n",
    "        model = siamese_CNN_contrastive((224, 224, 1))\n",
    "\n",
    "    if verbose:\n",
    "        model.summary()\n",
    "\n",
    "        tf.keras.utils.plot_model(\n",
    "            model,\n",
    "            show_shapes=True,\n",
    "            show_layer_names=True,\n",
    "            to_file=\"model_plot_contrastive.png\"\n",
    "        )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_setup_triplets(verbose=False):\n",
    "\n",
    "    if IS_TPU:\n",
    "        # instantiating the model in the strategy scope\n",
    "        # creates the model on the TPU\n",
    "        with tpu_strategy.scope():\n",
    "            model = siamese_CNN_triplets((224, 224, 1))\n",
    "    else:\n",
    "        model = siamese_CNN_triplets((224, 224, 1))\n",
    "\n",
    "    if verbose:\n",
    "        model.summary()\n",
    "\n",
    "        tf.keras.utils.plot_model(\n",
    "            model,\n",
    "            show_shapes=True,\n",
    "            show_layer_names=True,\n",
    "            to_file=\"model_plot_triplets.png\"\n",
    "        )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_setup_quadruplets(verbose=False):\n",
    "\n",
    "    if IS_TPU:\n",
    "        # instantiating the model in the strategy scope\n",
    "        # creates the model on the TPU\n",
    "        with tpu_strategy.scope():\n",
    "            model = siamese_CNN_quadruplets((224, 224, 1))\n",
    "    else:\n",
    "        model = siamese_CNN_quadruplets((224, 224, 1))\n",
    "\n",
    "    if verbose:\n",
    "        model.summary()\n",
    "\n",
    "        tf.keras.utils.plot_model(\n",
    "            model,\n",
    "            show_shapes=True,\n",
    "            show_layer_names=True,\n",
    "            to_file=\"model_plot_quadruplets.png\"\n",
    "        )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training(model, weights_name):\n",
    "    print(\"\\nStarting training!\\n\")\n",
    "\n",
    "    # hyperparameters\n",
    "    EPOCHS = 100  # number of epochs\n",
    "    BS = 128  # batch size\n",
    "\n",
    "    # callbacks\n",
    "    callbacks = [EarlyStopping(monitor='val_loss', patience=3, verbose=1,)]\n",
    "\n",
    "    history = model.fit(\n",
    "        pairs, targets,\n",
    "        batch_size=BS,\n",
    "        epochs=EPOCHS,\n",
    "        verbose=1,\n",
    "        callbacks=callbacks,\n",
    "        validation_split=0.3,\n",
    "    )\n",
    "\n",
    "    ALL_HISTORY.append(history)\n",
    "\n",
    "    print(\"\\nSaving weight for model...\", end=\"\")\n",
    "    siamese_contrastive.save_weights('./weights/{0}.h5'.format(weights_name))\n",
    "    print(\"saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy_roc(predictions, labels):\n",
    "    \"\"\"Compute ROC accuracyand threshold.\n",
    "\n",
    "    Also, plot FAR-FRR curves and P-R curves for input data.\n",
    "    \n",
    "    Args:\n",
    "        predictions -- np.array : array of predictions.\n",
    "        labels -- np.array : true labels (0 or 1).\n",
    "        plot_far_frr -- bool : plots curves of True.\n",
    "    \n",
    "    Returns:\n",
    "        max_acc -- float : maximum accuracy of model.\n",
    "        best_thresh --float : best threshold for the model.\n",
    "    \"\"\"\n",
    "    dmax = np.max(predictions)\n",
    "    dmin = np.min(predictions)\n",
    "\n",
    "    nsame = np.sum(labels == 1)  #similar\n",
    "    ndiff = np.sum(labels == 0)  #different\n",
    "\n",
    "    step = 0.01\n",
    "    max_acc = 0\n",
    "    best_thresh = -1\n",
    "\n",
    "    frr_plot = []\n",
    "    far_plot = []\n",
    "    pr_plot = []\n",
    "    re_plot = []\n",
    "\n",
    "    ds = []\n",
    "    for d in np.arange(dmin, dmax+step, step):\n",
    "        idx1 = predictions.ravel() <= d  # guessed genuine\n",
    "        idx2 = predictions.ravel() > d  # guessed forged\n",
    "\n",
    "        tp = float(np.sum(labels[idx1] == 1))\n",
    "        tn = float(np.sum(labels[idx2] == 0))\n",
    "        fp = float(np.sum(labels[idx1] == 0))\n",
    "        fn = float(np.sum(labels[idx2] == 1))\n",
    "\n",
    "        tpr = float(np.sum(labels[idx1] == 1)) / nsame       \n",
    "        tnr = float(np.sum(labels[idx2] == 0)) / ndiff\n",
    "        \n",
    "        \n",
    "        acc = 0.5 * (tpr + tnr)\n",
    "        pr = tp / (tp + fp)\n",
    "        re = tp / (tp + fn)\n",
    "       \n",
    "        if (acc > max_acc):\n",
    "            max_acc, best_thresh = acc, d\n",
    "\n",
    "        far = fp / (fp + tn)\n",
    "        frr = fn / (fn + tp)\n",
    "        frr_plot.append(frr)\n",
    "        pr_plot.append(pr)\n",
    "        re_plot.append(re)\n",
    "        far_plot.append(far)\n",
    "        ds.append(d)\n",
    "\n",
    "    plot_metrics = [ds, far_plot, frr_plot, pr_plot, re_plot]\n",
    "\n",
    "    return max_acc, best_thresh, plot_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation(model):\n",
    "    print(\"\\nEvaluating model...\", end=\"\")\n",
    "\n",
    "    pred = model.predict(pairs)\n",
    "    acc, thresh, plot_metrics = compute_accuracy_roc(pred, targets)\n",
    "    \n",
    "    print(\"evaluation finished!\\n\")\n",
    "\n",
    "    ACCURACIES.append(acc)\n",
    "    THRESHOLDS.append(thresh)\n",
    "    PLOTS.append(plot_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_history():\n",
    "    losses = ['loss', 'val_loss']\n",
    "\n",
    "    fig, ax = plt.subplots(1, 3, sharex=True, sharey=True, figsize=(13,4))\n",
    "    for i in range(3):\n",
    "        for x in losses:\n",
    "            ax[i].plot(ALL_HISTORY[i].history[x])\n",
    "            ax[i].set_title('Losses')\n",
    "\n",
    "        ax[i].legend(losses)\n",
    "        ax[i].grid(True)\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_plots(metrics):\n",
    "    ds = metrics[0]\n",
    "    far_plot = metrics[1]\n",
    "    frr_plot = metrics[2]\n",
    "    pr_plot = metrics[3]\n",
    "    re_plot = metrics[4]\n",
    "\n",
    "    fig = plt.figure(figsize=(15,7))\n",
    "    # error rate\n",
    "    ax = fig.add_subplot(121)\n",
    "    ax.plot(ds, far_plot, color='red')\n",
    "    ax.plot(ds, frr_plot, color='blue')\n",
    "    ax.set_title('Error rate')\n",
    "    ax.legend(['FAR', 'FRR'])\n",
    "    ax.set(xlabel = 'Thresholds', ylabel='Error rate')\n",
    "\n",
    "    # precision-recall curve\n",
    "    ax1 = fig.add_subplot(122)\n",
    "    ax1.plot(ds, pr_plot, color='green')\n",
    "    ax1.plot(ds, re_plot, color='magenta')\n",
    "    ax1.set_title('P-R curve')\n",
    "    ax1.legend(['Precision', 'Recall'])\n",
    "    ax.set(xlabel = 'Thresholds', ylabel='Error rate')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Everything put together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths to datasets\n",
    "PATHS = [\n",
    "    [\n",
    "        'data\\\\pickle-files\\\\cedar_pairs1_train.pickle',\n",
    "        'data\\\\pickle-files\\\\cedar_pairs1_pairs.pickle',\n",
    "        'data\\\\pickle-files\\\\cedar_pairs1_targets.pickle'\n",
    "    ],\n",
    "    [\n",
    "        'data\\\\pickle-files\\\\bengali_pairs1_train.pickle',\n",
    "        'data\\\\pickle-files\\\\bengali_pairs1_pairs.pickle',\n",
    "        'data\\\\pickle-files\\\\bengali_pairs1_targets.pickle'\n",
    "    ],\n",
    "    [\n",
    "        'data\\\\pickle-files\\\\hindi_pairs1_train.pickle',\n",
    "        'data\\\\pickle-files\\\\hindi_pairs1_pairs.pickle',\n",
    "        'data\\\\pickle-files\\\\hindi_pairs1_targets.pickle'\n",
    "    ]\n",
    "]\n",
    "\n",
    "# for kaggle\n",
    "# PATHS = [\n",
    "#     [\n",
    "#         '../usr/lib/preprocess/cedar_pairs1_train.pickle',\n",
    "#         '../usr/lib/preprocess/cedar_pairs1_pairs.pickle',\n",
    "#         '../usr/lib/preprocess/cedar_pairs1_targets.pickle'\n",
    "#     ],\n",
    "#     [\n",
    "#         '../usr/lib/preprocess/bengali_pairs1_train.pickle',\n",
    "#         '../usr/lib/preprocess/bengali_pairs1_pairs.pickle',\n",
    "#         '../usr/lib/preprocess/bengali_pairs1_targets.pickle'\n",
    "#     ],\n",
    "#     [\n",
    "#         '../usr/lib/preprocess/hindi_pairs1_train.pickle',\n",
    "#         '../usr/lib/preprocess/hindi_pairs1_pairs.pickle',\n",
    "#         '../usr/lib/preprocess/hindi_pairs1_targets.pickle'\n",
    "#     ]\n",
    "# ]\n",
    "\n",
    "# evaluation\n",
    "ALL_HISTORY = []\n",
    "ACCURACIES = []\n",
    "THRESHOLDS = []\n",
    "PLOTS = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_TPU = False\n",
    "\n",
    "if IS_TPU:\n",
    "    # detect and init the TPU\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n",
    "\n",
    "    # instantiate a distribution strategy\n",
    "    tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    data, pairs, targets = load_dataset(i)\n",
    "\n",
    "    data_shapes()\n",
    "\n",
    "    for bs in range(0, 3*42, 42):\n",
    "        plot_13(0+bs, 20+bs, 41+bs)\n",
    "        print()\n",
    "\n",
    "    if i == 0:\n",
    "        siamese_contrastive = model_setup(True)\n",
    "        model_training(siamese_contrastive, 'siamese_contrastive_cedar')\n",
    "\n",
    "    elif i == 1:\n",
    "        siamese_contrastive = model_setup()\n",
    "        model_training(siamese_contrastive, 'siamese_contrastive_bengali')\n",
    "\n",
    "    elif i == 2:\n",
    "        siamese_contrastive = model_setup()\n",
    "        model_training(siamese_contrastive, 'siamese_contrastive_hindi')\n",
    "\n",
    "    model_evaluation(siamese_contrastive)\n",
    "\n",
    "    del data\n",
    "    del pairs\n",
    "    del targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame.from_dict({'Accuracies': ACCURACIES,\n",
    "                          'Thresholds': THRESHOLDS})\n",
    "df.index = ['Cedar', 'BhSig260 Bengali', 'BhSig260 Hindi']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for met in PLOTS:\n",
    "    evaluation_plots(met)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2fc04cdb9730b0f31da2f90a691cdd0fa9da7bc1222eb1adb5ee73ed7bedeaa9"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
