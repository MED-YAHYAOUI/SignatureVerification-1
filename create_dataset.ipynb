{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataset\n",
    "Label the dataset and split into train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime as dt\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from pylab import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_pics(tensor, nb=0, template='{}', classnumber=None):\n",
    "    \"\"\"Function to plot dataset images.\n",
    "\n",
    "    Args:\n",
    "        tensor : dataset tensor.\n",
    "        nb -- int : number of images to be plotted.\n",
    "        template -- str : template for titles of subplots.\n",
    "        classnumber : titles of subplots.\n",
    "    \"\"\"\n",
    "    if nb == 0:\n",
    "        N = tensor.shape[0]\n",
    "    else:\n",
    "        N = min(nb, tensor.shape[0])\n",
    "    fig = plt.figure(figsize=(16,16))\n",
    "    nbligne = floor(N/20) + 1\n",
    "\n",
    "    for m in range(N):\n",
    "        subplot = fig.add_subplot(nbligne, min(N,20), m+1)\n",
    "        plt.imshow(tensor[m, :, :, 0], vmin=0, vmax=1, cmap='gray')\n",
    "\n",
    "        if classnumber != None:\n",
    "            subplot.title.set_text((template.format(classnumber)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_data(path):\n",
    "    \"\"\"Split data into data, labels.\n",
    "\n",
    "    Args:\n",
    "        path -- str : path for images.\n",
    "    \n",
    "    Returns:\n",
    "        data -- np.array : list of all images.\n",
    "        labels -- np.array : list of corresponding labels.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    labels = []\n",
    "    total_data = sorted(glob.glob(path +\"\\\\*\"))\n",
    "\n",
    "    for dirs in tqdm(total_data):\n",
    "        for img_path in sorted(glob.glob(f'{dirs}\\\\*')):\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            img = cv2.resize(img, (SIZE,SIZE))\n",
    "\n",
    "            data.append([img])\n",
    "            \n",
    "            rep = [\"0\", \"data\\\\CEDAR\\\\\", \"data\\\\BHSig26-Hindi\\\\\",\n",
    "                   \"data\\\\BHSig26-Bengali\\\\\"]\n",
    "            for i in rep:\n",
    "                dirs = dirs.replace(i, \"\")\n",
    "            labels.append(int(dirs))\n",
    "\n",
    "    data = np.array(data)\n",
    "    data = data.reshape(-1, SIZE, SIZE)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(path, classes):\n",
    "    \"\"\"Build dataset for train and test.\n",
    "\n",
    "    Returns:\n",
    "        dataset -- list : list of lengh classes containing images for each classes of shape (?, 224, 224, 1)\n",
    "    \"\"\"\n",
    "    data, labels = label_data(path)\n",
    "\n",
    "    x_train_origin, x_test_origin, y_train_origin, y_test_origin = train_test_split(data, labels, test_size=0.2)\n",
    "\n",
    "    assert keras_backend.image_data_format() == 'channels_last'\n",
    "    x_train_origin = x_train_origin.reshape(x_train_origin.shape[0], 224, 224, 1)\n",
    "    x_test_origin = x_test_origin.reshape(x_test_origin.shape[0], 224, 224, 1)\n",
    "\n",
    "    dataset_train = []\n",
    "    dataset_test = []\n",
    "\n",
    "    # Sorting images by classes and normalize values 0=>1\n",
    "    for n in tqdm(range(1,classes+1)):\n",
    "        images_class_n = np.asarray([row for idx, row in enumerate(x_train_origin) if y_train_origin[idx] == n])\n",
    "        dataset_train.append(images_class_n/255)\n",
    "\n",
    "        images_class_n = np.asarray([row for idx, row in enumerate(x_test_origin) if y_test_origin[idx] == n])\n",
    "        dataset_test.append(images_class_n/255)\n",
    "\n",
    "    return dataset_train, dataset_test, x_train_origin, y_train_origin, x_test_origin, y_test_origin"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2fc04cdb9730b0f31da2f90a691cdd0fa9da7bc1222eb1adb5ee73ed7bedeaa9"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
